---
title: "Economic Simulation Data Analysis"
author: "Chloe Denhart"
date: Sys.date()
format: html
editor: visual
---

## Data Analysis

This dataset is from a study conducted by 120 undergraduate students.

```{r}
# load in data
library(tidyverse)

pd <- read_csv("pd_data.csv")
head(pd)
colnames(pd)
```

\
This code will help us understand how many people cooperated versus defected in each experimental condition. "Does the experimental condition ('imagine' vs 'control') affect the likelihood of cooperating?" The participants played a total of

```{r}
# calculated the proportion of cooperation
pd <- pd |>
  mutate(coop_rate = coop / 20)
pd
```

Here we will summarize the average cooperation by condition

```{r}
# Calculate mean, standard deviation, and count for each group
pd %>%
  group_by(con) %>%
  summarise(
    mean_rate = mean(coop_rate, na.rm = TRUE),
    sd_rate = sd(coop_rate, na.rm = TRUE),
    n = n()
  )

```

Visualizing cooperation rate by condition

```{r}
pd %>%
  ggplot(aes(x = con, y = coop_rate, fill = con)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "yellow") +
  labs(
    title = "Cooperation Rates by Condition",
    x = "Condition",
    y = "Proportion of Rounds Cooperated"
  ) +
  theme_minimal()

```

Here we can clearly see that participants were more likely to cooperate when they were told a story about helping a partner or teammate rather than looking at random words and then going through the simulation

```{r}
# Compare mean cooperation rates statistically
t.test(coop_rate ~ con, data = pd)

```

This allows us to Check if the difference in average cooperation the imagine and control are statistically significant. Since we are looking at a 95% confidence interval and the p-value is 0.008394 (less than 0.05) our test is statistically significant. This is evidence that both of our groups differ (imagine and control).

This next test is a logistic regression of the first round, testing for demographics and empathy scores. Test whether participants in the “imagine” group were more likely to cooperate on the very first round, controlling for demographics and empathy scores.

```{r}
# Logistic regression: does imagining affect first round choice?
model <- glm(first.choice ~ con + sex + age + teq + iri_pt + iri_ec,
             data = pd, family = binomial)

summary(model)

```

The only statistically significant variable here for whether the participants decide to cooperate or defect on the first round is "conword" (or the condition word). Participants are less likely to cooperate on the first round when given words before they are prompted to make their decisions.

## Econometric Approach

We will run a linear regression to checks if the treatment increases total cooperation across all rounds and adjusts for demographics and empathy

```{r}
model2 <- lm(coop_rate ~ con + sex + age + teq + iri_pt + iri_ec, data = pd)
summary(model2)

```

This model predicts a participant’s **proportion of cooperative choices** (0–1) based on:

-   `con`: treatment (imag = reference, word = dummy `conword`)

-   `sex`: gender (F = reference, M = dummy)

-   `age`: participant’s age

-   `teq`, `iri_pt`, `iri_ec`: empathy-related scores

Participants who imagined helping their partner cooperated significantly more (M = 78%) than those in the control group (M = 60%). The treatment group’s cooperation rate was on average 18 percentage points higher, even after controlling for gender, age, and empathy scores. None of these other variables significantly predicted cooperation.

Next we will check for heteroskedasticity to make sure our p-values are valid and not too optimistic.

```{r}
# Plot residuals vs fitted values
plot(model2, which = 1)

```

This graph shows us that heteroskedasticity is not present.

We will now examine the round-level data to see how participants changed their behavior across rounds.

Checking for multicollinearity...

```{r}
library(car)
vif(model2)

```

| Predictor | VIF  | Interpretation                                             |
|-----------|------|------------------------------------------------------------|
| `con`     | 1.07 | No multicollinearity (ideal).                              |
| `sex`     | 1.07 | No multicollinearity.                                      |
| `age`     | 1.07 | No multicollinearity.                                      |
| `teq`     | 3.31 | Moderate correlation with others, but **not problematic**. |
| `iri_pt`  | 1.35 | No multicollinearity.                                      |
| `iri_ec`  | 3.42 | Moderate correlation with others, but still acceptable.    |

## Alex Data

The simulation we are using does not provide data for the partner "Alex". We have to write code to understand what to feed the LLM.

```{r}
library(tidyverse)

# One set of Alex's decisions (Random 50/50)
set.seed(123)  # For reproducibility
alex_choices <- tibble(
  round = 1:20,
  alex_choice = sample(c(0, 1), 20, replace = TRUE, prob = c(0.5, 0.5))
)

```

## LLM Data Analysis

```{r}
library(tidyverse)

# Load your new PD data
llm_pd <- read_csv("SURP LLM Responses PD.csv") |>
  mutate(coop_rate = coop / 20)  # Make sure coop_rate is calculated if needed

```

```{r}
# summarize cooperation by condition for LLM data
llm_summary <- llm_pd |>
  group_by(con) |>
  summarise(
    mean_rate = mean(coop_rate, na.rm = TRUE),
    sd_rate = sd(coop_rate, na.rm = TRUE),
    n = n()
  ) |>
  mutate(dataset = "LLM")
llm_summary

```

```{r}
# original summary
original_summary <- pd %>%
  group_by(con) %>%
  summarise(
    mean_rate = mean(coop_rate, na.rm = TRUE),
    sd_rate = sd(coop_rate, na.rm = TRUE),
    n = n()
  ) %>%
  mutate(dataset = "Original")

```

```{r}
comparison_summary <- bind_rows(original_summary, llm_summary)
comparison_summary
```

```{r}
# visualized comparison
library(ggplot2)

ggplot(comparison_summary, aes(x = con, y = mean_rate, fill = dataset)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Cooperation Rates: Original vs LLM PD",
       x = "Condition",
       y = "Mean Cooperation Rate") +
  theme_minimal()

```

Here we compare our human data to our LLMs data. We can see here that for the LLMs that have a much lower average cooperation rate. With the mean rate for the image condition differing by \~.34 with a similar standard deviation. Additionally, we have a difference in the mean rate for the word condition differing by \~.23 and a much smaller standard deviation of \~.1 compared to .39. Are LLMs less likely to cooperate because they lack human empathy and emotions?

```{r}
t.test(coop_rate ~ con, data = pd)      # Original
t.test(coop_rate ~ con, data = llm_pd)  # LLM
```

Our t-test for the LLMs is large at 0.7 where our t statistic is low at \~0.39 showing us that this is not statistically significant. In this case there is no evidence for a difference in the image condition versus the word condition, further allowing us to understand that LLMs still lack the human emotion necessary to make human-based decisions. The difference in significance could also be due the much smaller sample size in the LLM responses (a data limitation). The VIF results show no problematic multicollinearity in your regression predictors, which means your regression results are stable.

```{r}
# Distribution comparison
ggplot() +
  geom_density(data = pd, aes(x = coop_rate, fill = "Human"), alpha = 0.5) +
  geom_density(data = llm_pd, aes(x = coop_rate, fill = "LLM"), alpha = 0.5) +
  labs(title = "Cooperation Rate Distributions", x = "Cooperation Rate", fill = "Dataset")

```

Our human distribution (red) has a bimodal shape with two clear peaks, one peak close to 0 (very low cooperation rate) and another peak near 1 (very high cooperation rate).This suggests humans tend to cluster at extremes—either mostly cooperating or mostly defecting. LLM distribution (blue-green) shows a unimodal peak centered roughly around 0.25–0.35 cooperation rate. This indicates LLMs tend to have more moderate cooperation, generally cooperating less often and not clustering at the extremes. Can also mean they tend more to just go tit for tat.

## Personality Test Analysis

```{r}
# summary statistics for each survey across human generated and LLM generated responses
pd |>
  summarise(
    mean_teq = mean(teq, na.rm = TRUE),
    sd_teq = sd(teq, na.rm = TRUE),
    mean_iri_pt = mean(iri_pt, na.rm = TRUE),
    sd_iri_pt = sd(iri_pt, na.rm = TRUE),
    mean_iri_ec = mean(iri_ec, na.rm = TRUE),
    sd_iri_ec = sd(iri_ec, na.rm = TRUE),
    mean_iri_fs = mean(iri_fs, na.rm = TRUE),
    sd_iri_fs = sd(iri_fs, na.rm = TRUE),
    mean_iri_pd = mean(iri_pd, na.rm = TRUE),
    sd_iri_pd = sd(iri_pd, na.rm = TRUE)
  )

llm_pd |>
  summarise(
    mean_teq = mean(teq, na.rm = TRUE),
    sd_teq = sd(teq, na.rm = TRUE),
    mean_iri_pt = mean(iri_pt, na.rm = TRUE),
    sd_iri_pt = sd(iri_pt, na.rm = TRUE),
    mean_iri_ec = mean(iri_ec, na.rm = TRUE),
    sd_iri_ec = sd(iri_ec, na.rm = TRUE),
    mean_iri_fs = mean(iri_fs, na.rm = TRUE),
    sd_iri_fs = sd(iri_fs, na.rm = TRUE),
    mean_iri_pd = mean(iri_pd, na.rm = TRUE),
    sd_iri_pd = sd(iri_pd, na.rm = TRUE)
  )

```

For humans, mean teq was \~43.6 with sd of \~9.78. Mean iri_pt was \~17.9 with sd of \~4.42. Mean iri_ec was 18.266 with sd of \~5.07. Mean for iri_fs is 17.425 with sd of 5.43. Mean iri_pd is 12 with sd of 4.31.

For LLMs mean teq is \~41.388 with sd of 11.03. Mean iri_pt is 20.11 and sd is 5.779. Mean iri_ec 21.5 with sd of 6.12. Mean iri_fs 18.388 with sd of 5.95. Mean iri_pd 14.19 with sd of 4.9.

```{r}

# Assuming you have two datasets: pd (Humans) and llm_pd (LLMs)
# Add group labels
pd <- pd %>% mutate(group = "Human")
llm_pd <- llm_pd %>% mutate(group = "LLM")

# Combine
combined <- bind_rows(pd, llm_pd)

# Gather empathy scores into long format
empathy_long <- combined %>%
  select(group, teq, iri_pt, iri_ec, iri_fs, iri_pd) %>%
  pivot_longer(cols = -group, names_to = "measure", values_to = "score")

# Compute mean scores by group and measure
empathy_summary <- empathy_long %>%
  group_by(group, measure) %>%
  summarise(mean_score = mean(score, na.rm = TRUE), .groups = "drop")

```

```{r}
ggplot(empathy_summary, aes(x = measure, y = mean_score, fill = group)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Mean Empathy Scores by Group",
       x = "Empathy Measure",
       y = "Mean Score") +
  scale_fill_manual(values = c("Human" = "#E69F00", "LLM" = "#56B4E9")) +
  theme_minimal()

```

This shows us that almost every value is larger for the LLMs except for in the teq survey.

```{r}
library(psych)

numeric_data <- pd |> select(coop_rate, teq, iri_pt, iri_ec, iri_fs, iri_pd)

result <- corr.test(numeric_data)

print(result$r)    # correlations
print(result$p)    # p-values

```

This shows us theer are no strong correlations between the personality tests and the cooperation rates for humans.

```{r}
numeric_data <- llm_pd |> select(coop_rate, teq, iri_pt, iri_ec, iri_fs, iri_pd)

result <- corr.test(numeric_data)

print(result$r)    # correlations
print(result$p)    # p-values
```

For the LLMs we have moderate to strong positive correlations for all personality surveys.

```{r}
combined |>
  gather(key = "measure", value = "score", teq, iri_pt, iri_ec, iri_fs, iri_pd) |>
  ggplot(aes(x = score, fill = group)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ measure, scales = "free") +
  labs(title = "Empathy Score Distributions by Group")

```
