---
title: "Economic Simulation Data Analysis"
author: "Chloe Denhart"
date: Sys.date()
format: html
editor: visual
---

## Data Analysis

This dataset is from a study conducted by 120 undergraduate students.

```{r}
# load in data
library(tidyverse)

pd <- read_csv("pd_data.csv")
head(pd)
colnames(pd)
```

\
This code will help us understand how many people cooperated versus defected in each experimental condition. "Does the experimental condition ('imagine' vs 'control') affect the likelihood of cooperating?" The participants played a total of

```{r}
# calculated the proportion of cooperation
pd <- pd |>
  mutate(coop_rate = coop / 20)
pd
```

Here we will summarize the average cooperation by condition

```{r}
# Calculate mean, standard deviation, and count for each group
pd %>%
  group_by(con) %>%
  summarise(
    mean_rate = mean(coop_rate, na.rm = TRUE),
    sd_rate = sd(coop_rate, na.rm = TRUE),
    n = n()
  )

```

Visualizing cooperation rate by condition

```{r}
pd %>%
  ggplot(aes(x = con, y = coop_rate, fill = con)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "yellow") +
  labs(
    title = "Cooperation Rates by Condition",
    x = "Condition",
    y = "Proportion of Rounds Cooperated"
  ) +
  theme_minimal()

```

Here we can clearly see that participants were more likely to cooperate when they were told a story about helping a partner or teammate rather than looking at random words and then going through the simulation

```{r}
# Compare mean cooperation rates statistically
t.test(coop_rate ~ con, data = pd)

```

This allows us to Check if the difference in average cooperation the imagine and control are statistically significant. Since we are looking at a 95% confidence interval and the p-value is 0.008394 (less than 0.05) our test is statistically significant. This is evidence that both of our groups differ (imagine and control).

This next test is a logistic regression of the first round, testing for demographics and empathy scores. Test whether participants in the “imagine” group were more likely to cooperate on the very first round, controlling for demographics and empathy scores.

```{r}
# Logistic regression: does imagining affect first round choice?
model <- glm(first.choice ~ con + sex + age + teq + iri_pt + iri_ec,
             data = pd, family = binomial)

summary(model)

```

The only statistically significant variable here for whether the participants decide to cooperate or defect on the first round is "conword" (or the condition word). Participants are less likely to cooperate on the first round when given words before they are prompted to make their decisions.

## Econometric Approach

We will run a linear regression to checks if the treatment increases total cooperation across all rounds and adjusts for demographics and empathy

```{r}
model2 <- lm(coop_rate ~ con + sex + age + teq + iri_pt + iri_ec, data = pd)
summary(model2)

```

This model predicts a participant’s **proportion of cooperative choices** (0–1) based on:

-   `con`: treatment (imag = reference, word = dummy `conword`)

-   `sex`: gender (F = reference, M = dummy)

-   `age`: participant’s age

-   `teq`, `iri_pt`, `iri_ec`: empathy-related scores

Participants who imagined helping their partner cooperated significantly more (M = 78%) than those in the control group (M = 60%). The treatment group’s cooperation rate was on average 18 percentage points higher, even after controlling for gender, age, and empathy scores. None of these other variables significantly predicted cooperation.

Next we will check for heteroskedasticity to make sure our p-values are valid and not too optimistic.

```{r}
# Plot residuals vs fitted values
plot(model2, which = 1)

```

This graph shows us that heteroskedasticity is not present.

We will now examine the round-level data to see how participants changed their behavior across rounds.

Checking for multicollinearity...

```{r}
library(car)
vif(model2)

```

| Predictor | VIF  | Interpretation                                             |
|-----------|------|------------------------------------------------------------|
| `con`     | 1.07 | No multicollinearity (ideal).                              |
| `sex`     | 1.07 | No multicollinearity.                                      |
| `age`     | 1.07 | No multicollinearity.                                      |
| `teq`     | 3.31 | Moderate correlation with others, but **not problematic**. |
| `iri_pt`  | 1.35 | No multicollinearity.                                      |
| `iri_ec`  | 3.42 | Moderate correlation with others, but still acceptable.    |

## Alex Data
The simulation we are using does not provide data for the partner "Alex". We have to write code to understand what to feed the LLM.

```{r}
library(tidyverse)

# One set of Alex's decisions (Random 50/50)
set.seed(123)  # For reproducibility
alex_choices <- tibble(
  round = 1:20,
  alex_choice = sample(c(0, 1), 20, replace = TRUE, prob = c(0.5, 0.5))
)

```


## LLM Data Analysis

```{r}
library(tidyverse)

# Load your new PD data
llm_pd <- read_csv("SURP LLM Responses PD.csv") |>
  mutate(coop_rate = coop / 20)  # Make sure coop_rate is calculated if needed

```
```{r}
# summarize cooperation by condition for LLM data
llm_summary <- llm_pd |>
  group_by(con) |>
  summarise(
    mean_rate = mean(coop_rate, na.rm = TRUE),
    sd_rate = sd(coop_rate, na.rm = TRUE),
    n = n()
  ) |>
  mutate(dataset = "LLM")
llm_summary

```

```{r}
# original summary
original_summary <- pd %>%
  group_by(con) %>%
  summarise(
    mean_rate = mean(coop_rate, na.rm = TRUE),
    sd_rate = sd(coop_rate, na.rm = TRUE),
    n = n()
  ) %>%
  mutate(dataset = "Original")

```

```{r}
comparison_summary <- bind_rows(original_summary, llm_summary)
comparison_summary
```

```{r}
# visualized comparison
library(ggplot2)

ggplot(comparison_summary, aes(x = con, y = mean_rate, fill = dataset)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Cooperation Rates: Original vs LLM PD",
       x = "Condition",
       y = "Mean Cooperation Rate") +
  theme_minimal()

```

Here we compare our human data to our LLMs data. We can see here that for the LLMs that have a much lower average cooperation rate. With the mean rate for the image condition differing by ~.34 with a similar standard deviation. Additionally, we have a difference in the mean rate for the word condition differing by ~.23 and a much smaller standard deviation of ~.1 compared to .39. Are LLMs less likely to cooperate because they lack human empathy and emotions?

```{r}
t.test(coop_rate ~ con, data = pd)      # Original
t.test(coop_rate ~ con, data = llm_pd)  # LLM
```

